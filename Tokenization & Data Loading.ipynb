{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Collect & Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = [\n",
    "    \"The website is super slow today!\",  # Negative (0)\n",
    "    \"Great experience, everything is smooth.\",  # Positive (1)\n",
    "    \"I'm unable to access the website—error 500.\",  # Negative (0)\n",
    "    \"Fast loading times and great UI!\",  # Positive (1)\n",
    "    \"Pages keep crashing randomly.\"  # Negative (0)\n",
    "]\n",
    "labels = [0, 1, 0, 1, 0]  # Corresponding sentiment labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Tokenizer (Pretrained Tokenizer for LLMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rcman\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 4.5/10.0 MB 17.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.3/10.0 MB 15.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 14.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 14.1 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 39.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 5.4 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.28.1 safetensors-0.5.2 tokenizers-0.21.0 transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a397833e81e4ccdb9106a90b8291bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rcman\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rcman\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bd311377dd4b25af6d34e86ce9d1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6e23b5e2cf4021861076422f068490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5548593da26741b4952ce196b429b0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'website', 'is', 'super', 'slow', 'today', '!'], ['great', 'experience', ',', 'everything', 'is', 'smooth', '.'], ['i', \"'\", 'm', 'unable', 'to', 'access', 'the', 'website', '—', 'error', '500', '.'], ['fast', 'loading', 'times', 'and', 'great', 'ui', '!'], ['pages', 'keep', 'crashing', 'randomly', '.']]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokens = [tokenizer.tokenize(text) for text in feedback]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Tokenized Text into Numerical Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1996,  4037,  ...,     0,     0,     0],\n",
      "        [  101,  2307,  3325,  ...,     0,     0,     0],\n",
      "        [  101,  1045,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  3435, 10578,  ...,     0,     0,     0],\n",
      "        [  101,  5530,  2562,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(feedback, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "print(encoding.input_ids)  # Numerical representation of tokenized text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feedback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encoding\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39msqueeze(), torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize Dataset\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m dataset \u001b[38;5;241m=\u001b[39m SentimentDataset(feedback, labels, tokenizer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feedback' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(self.texts[idx], padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        return encoding.input_ids.squeeze(), torch.tensor(self.labels[idx])\n",
    "\n",
    "# Initialize Dataset\n",
    "dataset = SentimentDataset(feedback, labels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using DataLoader for Efficient Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3622667745.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    def collate_fn(batch)\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "# Collate Function for Padding and Batching\n",
    "from torch.utils.data import DataLoader\n",
    "def collate_fn(batch)\n",
    "    input_ids, labels = zip(*batch)\n",
    "    input_ids = torch.stack(input_ids)  # Convert list of tensors to a single tensor\n",
    "    labels = torch.tensor(labels)\n",
    "    return input_ids, labels\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn)\n",
    "\n",
    "# Iterate Over DataLoader\n",
    "for batch in dataloader:\n",
    "    input_ids, labels = batch\n",
    "    print(\"Batch Input IDs:\", input_ids)\n",
    "    print(\"Batch Labels:\", labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
